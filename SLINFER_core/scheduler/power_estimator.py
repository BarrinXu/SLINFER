models_power = {
    # template
    'MODEL_NAME': {
        'XPU': {
            'NODE_LABEL': {
                'prefill': [(1, 0), (128, 0), (256, 0), (512, 0), (1024, 0), (2048, 0), (4096, 0)],
                'decode': [
                    (512, [(1, 0), (2, 0), (4, 0), (8, 0), (16, 0), (32, 0), (64, 0), (128, 0)]),
                    (1024, [(1, 0), (2, 0), (4, 0), (8, 0), (16, 0), (32, 0), (64, 0)]),
                    (2048, [(1, 0), (2, 0), (4, 0), (8, 0), (16, 0), (32, 0), (64, 0)]),
                    (3950, [(1, 0), (2, 0), (4, 0), (8, 0), (16, 0), (32, 0)]),
                ],
                'sllm_concurrency': None,
                'sllm_share_concurrency': {2: None}
            }
        }
    },

    'llama-2-13b': {
        'cpu': {
            'cpu': {
                'prefill': [(1, 127), (128, 179), (256, 270), (512, 521), (1024, 1087), (2048, 2268), (4096, 5101)],
                'decode': [
                    (512, [(1, 128), (2, 133), (4, 138), (8, 149), (16, 170), (32, 209), (64, 298)]),
                    (1024, [(1, 130), (2, 135), (4, 145), (8, 165), (16, 205), (32, 277), (64, 436)]),
                    (2048, [(1, 134), (2, 143), (4, 162), (8, 199), (16, 275), (32, 412)]),
                    (3950, [(1, 142), (2, 158), (4, 193), (8, 264), (16, 406)])
                ],
                'sllm_concurrency': 6,
                # Same with no_share concurrency, since 13B occupies entire CPU.
                'sllm_share_concurrency': {2: 6}
            },
            'aliyun-16c': {
                'prefill': [(1, 130), (128, 277), (256, 465), (512, 911), (1024, 1901), (2048, 4017), (4096, 8966)],
                'decode': [
                    (512, [(1, 132), (2, 136), (4, 144), (8, 158), (16, 182), (32, 247)]),
                    (1024, [(1, 135), (2, 142), (4, 154), (8, 180), (16, 224), (32, 332)]),
                    (2048, [(1, 141), (2, 153), (4, 178), (8, 224), (16, 304)]),
                    (3950, [(1, 153), (2, 174), (4, 215), (8, 300)]),
                ],
                'sllm_concurrency': 4,
                'sllm_share_concurrency': {2: 4}
            },
        },
        'gpu': {
            'gpu': {
                'prefill': [(1, 23), (128, 32), (256, 44), (512, 81), (1024, 157), (2048, 283), (4096, 572)],
                'decode': [
                    (512, [(1, 22), (2, 22), (4, 24), (8, 26), (16, 31), (32, 39), (64, 53), (128, 92)]),
                    (1024, [(1, 22), (2, 22), (4, 24), (8, 26), (16, 32), (32, 44), (64, 66)]),
                    (2048, [(1, 22), (2, 23), (4, 26), (8, 31), (16, 41), (32, 59)]),
                    (3950, [(1, 23), (2, 25), (4, 29), (8, 40), (16, 56)])
                ],
                'sllm_concurrency': 16,
                'sllm_share_concurrency': {2: 4}
            },
        }
    },
    'llama-3.1-8b': {
        'gpu': {
            'gpu': {
                'prefill': [(1, 17), (128, 23), (256, 29), (512, 45), (1024, 83), (2048, 160), (4096, 326), (8192, 687),
                            (16384, 1534), (32768, 3781)],
                'decode': [
                    (1024, [(1, 14), (2, 15), (4, 15), (8, 16), (16, 18), (32, 23), (64, 32), (128, 49), (256, 97)]),
                    (2048, [(1, 15), (2, 15), (4, 16), (8, 17), (16, 19), (32, 27), (64, 40), (128, 60)]),
                    (4096, [(1, 15), (2, 15), (4, 16), (8, 18), (16, 23), (32, 36), (64, 54)]),
                    (8192, [(1, 15), (2, 16), (4, 18), (8, 22), (16, 29), (32, 51)]),
                    (16384, [(1, 16), (2, 18), (4, 21), (8, 28), (16, 41)]),
                    (32768, [(1, 17), (2, 21), (4, 27), (8, 42)]),
                ],
                'sllm_concurrency': 32,
                'sllm_share_concurrency': {2: 12}
            }
        },
        'cpu': {
            'cpu': {
                'prefill': [(1, 74), (128, 111), (256, 178), (512, 339), (1024, 679), (2048, 1427), (4096, 3169),
                            (8192, 7707),
                            (16384, 22983), (32768, 84790)],
                'decode': [
                    (1024, [(1, 74), (2, 76), (4, 79), (8, 84), (16, 94), (32, 113), (64, 169)]),
                    (2048, [(1, 75), (2, 78), (4, 82), (8, 91), (16, 106), (32, 141), (64, 218)]),
                    (4096, [(1, 76), (2, 81), (4, 89), (8, 103), (16, 133), (32, 198)]),
                    (8192, [(1, 80), (2, 87), (4, 101), (8, 128), (16, 184)]),
                    (16384, [(1, 88), (2, 100), (4, 126), (8, 180)]),
                    (32768, [(1, 98), (2, 125), (4, 177), (8, 286)]),
                ],
                'sllm_concurrency': 15,
                # We set 2 for longbench, the old value is 4.
                'sllm_share_concurrency': {2: 4}
            }
        }
    },
    'llama-2-7b': {
        'cpu': {
            'cpu': {
                'prefill': [(1, 70), (128, 99), (256, 149), (512, 285), (1024, 567), (2048, 1178), (4096, 2748)],
                'decode': [
                    (512, [(1, 70), (2, 72), (4, 77), (8, 84), (16, 97), (32, 131), (64, 193), (128, 316)]),
                    (1024, [(1, 71), (2, 75), (4, 81), (8, 94), (16, 120), (32, 196), (64, 297)]),
                    (2048, [(1, 74), (2, 81), (4, 92), (8, 116), (16, 163), (32, 286), (64, 479)]),
                    (3950, [(1, 80), (2, 90), (4, 112), (8, 156), (16, 244), (32, 459)]),
                ],
                'sllm_concurrency': 15,
                'sllm_share_concurrency': {2: 4}
            },
            'aliyun-16c': {
                'prefill': [(1, 88), (128, 148), (256, 246), (512, 488), (1024, 972), (2048, 2068), (4096, 4708)],
                'decode': [
                    (512, [(1, 72), (2, 75), (4, 80), (8, 90), (16, 106), (32, 156), (64, 257)]),
                    (1024, [(1, 75), (2, 79), (4, 87), (8, 102), (16, 135), (32, 206), (64, 350)]),
                    (2048, [(1, 78), (2, 86), (4, 100), (8, 130), (16, 192), (32, 320)]),
                    (3950, [(1, 84), (2, 97), (4, 125), (8, 177), (16, 297)]),
                ],
                'sllm_concurrency': 10,
                'sllm_share_concurrency': {2: 3}
            },
            'aliyun-8c': {
                'prefill': [(1, 107), (128, 280), (256, 500), (512, 1042), (1024, 2169), (2048, 4591), (4096, 9832)],
                'decode': [
                    (512, [(1, 110), (2, 114), (4, 120), (8, 135), (16, 165), (32, 245)]),
                    (1024, [(1, 112), (2, 119), (4, 132), (8, 158), (16, 210)]),
                    (2048, [(1, 119), (2, 135), (4, 156), (8, 225)]),
                    (3950, [(1, 130), (2, 153), (4, 199), (8, 290)]),
                ],
                'sllm_concurrency': None,
                'sllm_share_concurrency': {2: None}
            },
        },
        'gpu': {
            'gpu': {
                'prefill': [(1, 20), (128, 24), (256, 30), (512, 50), (1024, 89), (2048, 169), (4096, 336)],
                'decode': [
                    (512, [(1, 14), (2, 14), (4, 15), (8, 17), (16, 20), (32, 26), (64, 39), (128, 59)]),
                    (1024, [(1, 14), (2, 14), (4, 15), (8, 18), (16, 22), (32, 30), (64, 47), (96, 67)]),
                    (2048, [(1, 14), (2, 15), (4, 17), (8, 22), (16, 28), (32, 40), (48, 56)]),
                    (3950, [(1, 15), (2, 16), (4, 19), (8, 28), (16, 38), (24, 49)])
                ],
                'sllm_concurrency': 32,
                'sllm_share_concurrency': {2: 12}
            },
        }
    },
    'llama-3.2-3b': {
        'cpu': {
            'cpu': {
                'prefill': [(1, 39), (128, 58), (256, 87), (512, 166), (1024, 339), (2048, 703), (4096, 1616)],
                'decode': [
                    (512, [(1, 39), (2, 40), (4, 42), (8, 45), (16, 54), (32, 62), (64, 96), (128, 160), (256, 300)]),
                    (1024, [(1, 39), (2, 40), (4, 44), (8, 48), (16, 58), (32, 74), (64, 119), (128, 210), (256, 390)]),
                    (2048, [(1, 40), (2, 43), (4, 47), (8, 53), (16, 66), (32, 100), (64, 168), (128, 302)]),
                    (3950, [(1, 41), (2, 45), (4, 51), (8, 62), (16, 85), (32, 144), (64, 257)])
                ],
                'sllm_concurrency': 59,
                'sllm_share_concurrency': {2: 23}
            },
            'aliyun-16c': {
                'prefill': [(1, 41), (128, 83), (256, 137), (512, 259), (1024, 539), (2048, 1143), (4096, 2629)],
                'decode': [
                    (512, [(1, 40), (2, 41), (4, 45), (8, 48), (16, 54), (32, 74), (64, 121), (128, 211)]),
                    (1024, [(1, 41), (2, 43), (4, 47), (8, 52), (16, 63), (32, 92), (64, 155), (128, 275)]),
                    (2048, [(1, 42), (2, 45), (4, 51), (8, 60), (16, 81), (32, 126), (64, 221)]),
                    (3950, [(1, 44), (2, 50), (4, 58), (8, 74), (16, 113), (32, 189)]),
                ],
                'sllm_concurrency': 32,
                'sllm_share_concurrency': {2: 15}
            },
            'aliyun-8c': {
                'prefill': [(1, 58), (128, 150), (256, 257), (512, 521), (1024, 1131), (2048, 2390), (4096, 5356)],
                'decode': [
                    (512, [(1, 58), (2, 61), (4, 64), (8, 69), (16, 81), (32, 122), (64, 206)]),
                    (1024, [(1, 59), (2, 62), (4, 67), (8, 77), (16, 97), (32, 153), (64, 265)]),
                    (2048, [(1, 61), (2, 66), (4, 74), (8, 92), (16, 129), (32, 214)]),
                    (3950, [(1, 65), (2, 73), (4, 87), (8, 120), (16, 184), (32, 330)]),
                ],
                'sllm_concurrency': 20,
                'sllm_share_concurrency': {2: 7}
            },
        },
        'gpu': {
            'gpu': {
                'prefill': [(1, 20), (128, 20), (256, 21), (512, 28), (1024, 45), (2048, 82), (4096, 163)],
                'decode': [
                    (512, [(1, 12), (2, 12), (4, 13), (8, 13), (16, 15), (32, 19), (64, 31), (128, 42), (256, 75)]),
                    (1024, [(1, 12), (2, 12), (4, 13), (8, 13), (16, 15), (32, 20), (64, 34), (128, 50), (256, 99)]),
                    (2048, [(1, 12), (2, 12), (4, 13), (8, 13), (16, 16), (32, 22), (64, 34), (128, 59)]),
                    (3950, [(1, 12), (2, 12), (4, 13), (8, 14), (16, 18), (32, 28), (64, 45)])
                ],
                'sllm_concurrency': 160,
                'sllm_share_concurrency': {2: 71}
            },
        },
    },
}


def cal_interplot(x1, y1, x2, y2, now_x):
    return y1 + (y2 - y1) * (now_x - x1) / (x2 - x1)


def cal_now_y_in_xy_list(xy_list, now_x):
    if now_x <= xy_list[0][0]:
        return xy_list[0][1]
    if now_x >= xy_list[-1][0]:
        return xy_list[-1][1] * now_x / xy_list[-1][0]
    for i in range(len(xy_list)):
        if xy_list[i][0] >= now_x:
            assert i > 0
            return cal_interplot(xy_list[i - 1][0], xy_list[i - 1][1], xy_list[i][0], xy_list[i][1], now_x)
    raise Exception


def cal_now_y_in_x_xy_list_list(x_xy_list_list, outer_x, inner_x):
    if outer_x <= x_xy_list_list[0][0]:
        return cal_now_y_in_xy_list(x_xy_list_list[0][1], inner_x)
    if outer_x >= x_xy_list_list[-1][0]:
        return cal_now_y_in_xy_list(x_xy_list_list[-1][1], inner_x) * outer_x / x_xy_list_list[-1][0]
    for i in range(len(x_xy_list_list)):
        if x_xy_list_list[i][0] >= outer_x:
            assert i > 0
            lft_y = cal_now_y_in_xy_list(x_xy_list_list[i - 1][1], inner_x)
            rgt_y = cal_now_y_in_xy_list(x_xy_list_list[i][1], inner_x)
            return cal_interplot(x_xy_list_list[i - 1][0], lft_y, x_xy_list_list[i][0], rgt_y, outer_x)
    raise Exception


def estimate_duration(model_type, node_type, node_label, avg_input_length, batch_size, stage_type):
    safety_factor = 1.05
    if node_type == 'cpu':
        safety_factor = 1.1
        if stage_type == 'decode':
            if '8c' in node_label or '16c' in node_label:
                safety_factor = 1.5

    if stage_type == 'prefill':
        return cal_now_y_in_xy_list(models_power[model_type][node_type][node_label]['prefill'],
                                    avg_input_length) * safety_factor / 1000
    elif stage_type == 'decode':
        return cal_now_y_in_x_xy_list_list(models_power[model_type][node_type][node_label][stage_type],
                                           avg_input_length, batch_size) * safety_factor / 1000
    else:
        raise Exception


def get_serverlessllm_concurrency(model_type, node_type, node_label, sllm_max_shares):
    assert sllm_max_shares > 0
    if sllm_max_shares == 1:
        return models_power[model_type][node_type][node_label]['sllm_concurrency']
    else:
        return models_power[model_type][node_type][node_label]['sllm_share_concurrency'][sllm_max_shares]
